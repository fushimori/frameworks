{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №5: Градиентный бустинг (Gradient Boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "plt.style.use('default')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Собственная реализация решающего дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union, Optional, Tuple, List\n",
    "\n",
    "\n",
    "class CustomDecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, criterion='gini', random_state=42):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.criterion = criterion\n",
    "        self.random_state = random_state\n",
    "        self.tree = None\n",
    "        self.feature_importances_ = None\n",
    "        self.n_features_ = None\n",
    "        self.n_classes_ = None\n",
    "        \n",
    "    def _gini_impurity(self, y):\n",
    "        if len(y) == 0:\n",
    "            return 0.0\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        return 1 - np.sum(probabilities ** 2)\n",
    "    \n",
    "    def _entropy(self, y):\n",
    "        if len(y) == 0:\n",
    "            return 0.0\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        probabilities = probabilities[probabilities > 0]\n",
    "        return -np.sum(probabilities * np.log2(probabilities))\n",
    "    \n",
    "    def _information_gain(self, parent_y, left_y, right_y):\n",
    "        n = len(parent_y)\n",
    "        if n == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        if self.criterion == 'gini':\n",
    "            parent_impurity = self._gini_impurity(parent_y)\n",
    "            left_impurity = self._gini_impurity(left_y)\n",
    "            right_impurity = self._gini_impurity(right_y)\n",
    "        else:\n",
    "            parent_impurity = self._entropy(parent_y)\n",
    "            left_impurity = self._entropy(left_y)\n",
    "            right_impurity = self._entropy(right_y)\n",
    "        \n",
    "        weighted_child_impurity = (len(left_y) * left_impurity + len(right_y) * right_impurity) / n\n",
    "        return parent_impurity - weighted_child_impurity\n",
    "    \n",
    "    def _best_split(self, X, y):\n",
    "        best_gain = -1\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        n_features = X.shape[1]\n",
    "        \n",
    "        for feature in range(n_features):\n",
    "            values = X[:, feature]\n",
    "            unique_values = np.unique(values)\n",
    "            \n",
    "            for i in range(len(unique_values) - 1):\n",
    "                threshold = (unique_values[i] + unique_values[i + 1]) / 2\n",
    "                left_mask = values <= threshold\n",
    "                right_mask = ~left_mask\n",
    "                \n",
    "                if np.sum(left_mask) == 0 or np.sum(right_mask) == 0:\n",
    "                    continue\n",
    "                \n",
    "                left_y = y[left_mask]\n",
    "                right_y = y[right_mask]\n",
    "                gain = self._information_gain(y, left_y, right_y)\n",
    "                \n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "        \n",
    "        return best_feature, best_threshold, best_gain\n",
    "    \n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or \\\n",
    "           n_samples < self.min_samples_split or \\\n",
    "           len(np.unique(y)) == 1:\n",
    "            unique_classes, counts = np.unique(y, return_counts=True)\n",
    "            return int(unique_classes[np.argmax(counts)])\n",
    "        \n",
    "        best_feature, best_threshold, best_gain = self._best_split(X, y)\n",
    "        \n",
    "        if best_feature is None or best_gain <= 0:\n",
    "            unique_classes, counts = np.unique(y, return_counts=True)\n",
    "            return int(unique_classes[np.argmax(counts)])\n",
    "        \n",
    "        node = {'feature': best_feature, 'threshold': best_threshold, 'gain': best_gain, 'left': None, 'right': None}\n",
    "        \n",
    "        left_mask = X[:, best_feature] <= best_threshold\n",
    "        right_mask = ~left_mask\n",
    "        \n",
    "        if self.feature_importances_ is not None:\n",
    "            self.feature_importances_[best_feature] += best_gain * n_samples\n",
    "        \n",
    "        node['left'] = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "        node['right'] = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "        \n",
    "        return node\n",
    "    \n",
    "    def _predict_sample(self, x, node):\n",
    "        if isinstance(node, (int, np.integer)):\n",
    "            return node\n",
    "        \n",
    "        if x[node['feature']] <= node['threshold']:\n",
    "            return self._predict_sample(x, node['left'])\n",
    "        else:\n",
    "            return self._predict_sample(x, node['right'])\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_array = X.values if hasattr(X, 'values') else np.array(X)\n",
    "        y_array = y.values if hasattr(y, 'values') else np.array(y)\n",
    "        \n",
    "        if X_array.shape[0] != len(y_array):\n",
    "            raise ValueError(\"Размеры не совпадают\")\n",
    "        \n",
    "        self.n_features_ = X_array.shape[1]\n",
    "        self.feature_importances_ = np.zeros(self.n_features_)\n",
    "        self.n_classes_ = len(np.unique(y_array))\n",
    "        \n",
    "        np.random.seed(self.random_state)\n",
    "        self.tree = self._build_tree(X_array, y_array)\n",
    "        \n",
    "        total_gain = np.sum(self.feature_importances_)\n",
    "        if total_gain > 0:\n",
    "            self.feature_importances_ /= total_gain\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.tree is None:\n",
    "            raise ValueError(\"Модель не обучена\")\n",
    "        \n",
    "        X_array = X.values if hasattr(X, 'values') else np.array(X)\n",
    "        return np.array([self._predict_sample(x, self.tree) for x in X_array])\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        y_true = y.values if hasattr(y, 'values') else y\n",
    "        return np.mean(y_true == y_pred)\n",
    "\n",
    "\n",
    "class CustomDecisionTreeRegressor:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, criterion='squared_error', random_state=42):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.criterion = criterion\n",
    "        self.random_state = random_state\n",
    "        self.tree = None\n",
    "        self.feature_importances_ = None\n",
    "        self.n_features_ = None\n",
    "        \n",
    "    def _mse(self, y):\n",
    "        if len(y) == 0:\n",
    "            return 0.0\n",
    "        mean_y = np.mean(y)\n",
    "        return np.mean((y - mean_y) ** 2)\n",
    "    \n",
    "    def _reduction_in_impurity(self, parent_y, left_y, right_y):\n",
    "        n = len(parent_y)\n",
    "        if n == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        parent_impurity = self._mse(parent_y)\n",
    "        left_impurity = self._mse(left_y)\n",
    "        right_impurity = self._mse(right_y)\n",
    "        \n",
    "        weighted_child_impurity = (len(left_y) * left_impurity + len(right_y) * right_impurity) / n\n",
    "        return parent_impurity - weighted_child_impurity\n",
    "    \n",
    "    def _best_split(self, X, y):\n",
    "        best_gain = -1\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        n_features = X.shape[1]\n",
    "        \n",
    "        for feature in range(n_features):\n",
    "            values = X[:, feature]\n",
    "            unique_values = np.unique(values)\n",
    "            \n",
    "            for i in range(len(unique_values) - 1):\n",
    "                threshold = (unique_values[i] + unique_values[i + 1]) / 2\n",
    "                left_mask = values <= threshold\n",
    "                right_mask = ~left_mask\n",
    "                \n",
    "                if np.sum(left_mask) == 0 or np.sum(right_mask) == 0:\n",
    "                    continue\n",
    "                \n",
    "                left_y = y[left_mask]\n",
    "                right_y = y[right_mask]\n",
    "                gain = self._reduction_in_impurity(y, left_y, right_y)\n",
    "                \n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "        \n",
    "        return best_feature, best_threshold, best_gain\n",
    "    \n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or n_samples < self.min_samples_split:\n",
    "            return float(np.mean(y))\n",
    "        \n",
    "        if len(np.unique(y)) == 1:\n",
    "            return float(y[0])\n",
    "        \n",
    "        best_feature, best_threshold, best_gain = self._best_split(X, y)\n",
    "        \n",
    "        if best_feature is None or best_gain <= 0:\n",
    "            return float(np.mean(y))\n",
    "        \n",
    "        node = {'feature': best_feature, 'threshold': best_threshold, 'gain': best_gain, 'left': None, 'right': None}\n",
    "        \n",
    "        left_mask = X[:, best_feature] <= best_threshold\n",
    "        right_mask = ~left_mask\n",
    "        \n",
    "        if self.feature_importances_ is not None:\n",
    "            self.feature_importances_[best_feature] += best_gain * n_samples\n",
    "        \n",
    "        node['left'] = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "        node['right'] = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "        \n",
    "        return node\n",
    "    \n",
    "    def _predict_sample(self, x, node):\n",
    "        if isinstance(node, (int, float, np.number)):\n",
    "            return float(node)\n",
    "        \n",
    "        if x[node['feature']] <= node['threshold']:\n",
    "            return self._predict_sample(x, node['left'])\n",
    "        else:\n",
    "            return self._predict_sample(x, node['right'])\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_array = X.values if hasattr(X, 'values') else np.array(X)\n",
    "        y_array = y.values if hasattr(y, 'values') else np.array(y)\n",
    "        \n",
    "        if X_array.shape[0] != len(y_array):\n",
    "            raise ValueError(\"Размеры не совпадают\")\n",
    "        \n",
    "        self.n_features_ = X_array.shape[1]\n",
    "        self.feature_importances_ = np.zeros(self.n_features_)\n",
    "        \n",
    "        np.random.seed(self.random_state)\n",
    "        self.tree = self._build_tree(X_array, y_array)\n",
    "        \n",
    "        total_gain = np.sum(self.feature_importances_)\n",
    "        if total_gain > 0:\n",
    "            self.feature_importances_ /= total_gain\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.tree is None:\n",
    "            raise ValueError(\"Модель не обучена\")\n",
    "        \n",
    "        X_array = X.values if hasattr(X, 'values') else np.array(X)\n",
    "        return np.array([self._predict_sample(x, self.tree) for x in X_array])\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        y_true = y.values if hasattr(y, 'values') else y\n",
    "        ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "        ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "        return 0.0 if ss_tot == 0 else 1 - (ss_res / ss_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Собственная реализация градиентного бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGradientBoostingClassifier:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3, min_samples_split=2, random_state=42):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        self.trees = []\n",
    "        self.feature_importances_ = None\n",
    "        self.n_features_ = None\n",
    "        self.n_classes_ = None\n",
    "        self.base_prediction_ = None\n",
    "        \n",
    "    def _log_odds(self, p):\n",
    "        p = np.clip(p, 1e-15, 1 - 1e-15)\n",
    "        return np.log(p / (1 - p))\n",
    "    \n",
    "    def _sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_array = X.values if hasattr(X, 'values') else np.array(X)\n",
    "        y_array = y.values if hasattr(y, 'values') else np.array(y)\n",
    "        \n",
    "        if X_array.shape[0] != len(y_array):\n",
    "            raise ValueError(\"Размеры не совпадают\")\n",
    "        \n",
    "        self.n_features_ = X_array.shape[1]\n",
    "        self.n_classes_ = len(np.unique(y_array))\n",
    "        \n",
    "        if self.n_classes_ > 2:\n",
    "            raise ValueError(\"Только бинарная классификация поддерживается\")\n",
    "        \n",
    "        np.random.seed(self.random_state)\n",
    "        self.base_prediction_ = np.log(np.mean(y_array) / (1 - np.mean(y_array)))\n",
    "        F = np.full(len(y_array), self.base_prediction_)\n",
    "        self.trees = []\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            p_current = self._sigmoid(F)\n",
    "            residuals = y_array - p_current\n",
    "            \n",
    "            tree = CustomDecisionTreeRegressor(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                criterion='squared_error',\n",
    "                random_state=self.random_state + i\n",
    "            )\n",
    "            tree.fit(X_array, residuals)\n",
    "            \n",
    "            tree_pred = tree.predict(X_array)\n",
    "            F += self.learning_rate * tree_pred\n",
    "            self.trees.append(tree)\n",
    "            \n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(f\"Обучено деревьев: {i + 1}/{self.n_estimators}\")\n",
    "        \n",
    "        self.feature_importances_ = np.zeros(self.n_features_)\n",
    "        for tree in self.trees:\n",
    "            tree_importance = tree.feature_importances_\n",
    "            self.feature_importances_ += tree_importance\n",
    "        \n",
    "        total_importance = np.sum(self.feature_importances_)\n",
    "        if total_importance > 0:\n",
    "            self.feature_importances_ /= total_importance\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if not self.trees:\n",
    "            raise ValueError(\"Модель не обучена\")\n",
    "        \n",
    "        X_array = X.values if hasattr(X, 'values') else np.array(X)\n",
    "        F = np.full(X_array.shape[0], self.base_prediction_)\n",
    "        \n",
    "        for tree in self.trees:\n",
    "            F += self.learning_rate * tree.predict(X_array)\n",
    "        \n",
    "        probabilities = np.zeros((X_array.shape[0], self.n_classes_))\n",
    "        probabilities[:, 1] = self._sigmoid(F)\n",
    "        probabilities[:, 0] = 1 - probabilities[:, 1]\n",
    "        \n",
    "        return probabilities\n",
    "    \n",
    "    def predict(self, X):\n",
    "        probabilities = self.predict_proba(X)\n",
    "        return (probabilities[:, 1] >= 0.5).astype(int)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        y_true = y.values if hasattr(y, 'values') else y\n",
    "        return np.mean(y_true == y_pred)\n",
    "\n",
    "\n",
    "class CustomGradientBoostingRegressor:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3, min_samples_split=2, random_state=42):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        self.trees = []\n",
    "        self.feature_importances_ = None\n",
    "        self.n_features_ = None\n",
    "        self.base_prediction_ = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X_array = X.values if hasattr(X, 'values') else np.array(X)\n",
    "        y_array = y.values if hasattr(y, 'values') else np.array(y)\n",
    "        \n",
    "        if X_array.shape[0] != len(y_array):\n",
    "            raise ValueError(\"Размеры не совпадают\")\n",
    "        \n",
    "        self.n_features_ = X_array.shape[1]\n",
    "        np.random.seed(self.random_state)\n",
    "        self.base_prediction_ = np.mean(y_array)\n",
    "        F = np.full(len(y_array), self.base_prediction_)\n",
    "        self.trees = []\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            residuals = y_array - F\n",
    "            \n",
    "            tree = CustomDecisionTreeRegressor(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                criterion='squared_error',\n",
    "                random_state=self.random_state + i\n",
    "            )\n",
    "            tree.fit(X_array, residuals)\n",
    "            \n",
    "            tree_pred = tree.predict(X_array)\n",
    "            F += self.learning_rate * tree_pred\n",
    "            self.trees.append(tree)\n",
    "            \n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(f\"Обучено деревьев: {i + 1}/{self.n_estimators}\")\n",
    "        \n",
    "        self.feature_importances_ = np.zeros(self.n_features_)\n",
    "        for tree in self.trees:\n",
    "            tree_importance = tree.feature_importances_\n",
    "            self.feature_importances_ += tree_importance\n",
    "        \n",
    "        total_importance = np.sum(self.feature_importances_)\n",
    "        if total_importance > 0:\n",
    "            self.feature_importances_ /= total_importance\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if not self.trees:\n",
    "            raise ValueError(\"Модель не обучена\")\n",
    "        \n",
    "        X_array = X.values if hasattr(X, 'values') else np.array(X)\n",
    "        prediction = np.full(X_array.shape[0], self.base_prediction_)\n",
    "        \n",
    "        for tree in self.trees:\n",
    "            prediction += self.learning_rate * tree.predict(X_array)\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        y_true = y.values if hasattr(y, 'values') else y\n",
    "        ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "        ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "        return 0.0 if ss_tot == 0 else 1 - (ss_res / ss_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Загрузка и изучение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка и преобразование данных...\n",
      "Загружено фильмов: 45466\n",
      "Анализ целевых переменных:\n",
      "Доля коммерчески успешных фильмов: 59.43%\n",
      "Количество фильмов для анализа: 5381\n",
      "Создание признаков:\n",
      "Признаки созданы\n",
      "Подготовка датасетов для ML:\n",
      "Датасет для классификации: 5381 объектов, 9 признаков\n",
      "Датасет для регрессии: 5381 объектов, 9 признаков\n",
      "Данные подготовлены для машинного обучения\n",
      "Информация о данных:\n",
      "Классификация: 5381 объектов, 9 признаков\n",
      "Регрессия: 5381 объектов, 9 признаков\n",
      "Баланс классов: {1: 3198, 0: 2183}\n",
      "Статистика рейтинга: мин=0.00, макс=9.10, среднее=6.27\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_data(dataset_path='./movies_dataset'):\n",
    "    print(\"Загрузка и преобразование данных...\")\n",
    "    \n",
    "    movies = pd.read_csv(f'{dataset_path}/movies_metadata.csv', low_memory=False)\n",
    "    print(f\"Загружено фильмов: {len(movies)}\")\n",
    "    \n",
    "    movies_clean = _analyze_target_variables(movies)\n",
    "    movies_processed = _feature_engineering(movies_clean)\n",
    "    X_class, y_class, X_reg, y_reg, features = _create_ml_datasets(movies_processed)\n",
    "    \n",
    "    print(\"Данные подготовлены для машинного обучения\")\n",
    "    return X_class, y_class, X_reg, y_reg, features\n",
    "\n",
    "def _analyze_target_variables(movies):\n",
    "    print(\"Анализ целевых переменных:\")\n",
    "    \n",
    "    movies_clean = movies.copy()\n",
    "    movies_clean['revenue'] = pd.to_numeric(movies_clean['revenue'], errors='coerce')\n",
    "    movies_clean['budget'] = pd.to_numeric(movies_clean['budget'], errors='coerce')\n",
    "    \n",
    "    movies_clean = movies_clean[\n",
    "        (movies_clean['revenue'].notna()) & \n",
    "        (movies_clean['budget'].notna()) & \n",
    "        (movies_clean['revenue'] > 0) & \n",
    "        (movies_clean['budget'] > 0)\n",
    "    ]\n",
    "    \n",
    "    movies_clean['commercial_success'] = (movies_clean['revenue'] > movies_clean['budget'] * 1.5).astype(int)\n",
    "    \n",
    "    success_rate = movies_clean['commercial_success'].mean()\n",
    "    print(f\"Доля коммерчески успешных фильмов: {success_rate:.2%}\")\n",
    "    print(f\"Количество фильмов для анализа: {len(movies_clean)}\")\n",
    "    \n",
    "    return movies_clean\n",
    "\n",
    "def _feature_engineering(movies_clean):\n",
    "    print(\"Создание признаков:\")\n",
    "    \n",
    "    numeric_features = ['budget', 'popularity', 'runtime', 'vote_count']\n",
    "    \n",
    "    for feature in numeric_features:\n",
    "        movies_clean[feature] = pd.to_numeric(movies_clean[feature], errors='coerce')\n",
    "        movies_clean[feature].fillna(movies_clean[feature].median(), inplace=True)\n",
    "    \n",
    "    def extract_main_genre(genres_str):\n",
    "        try:\n",
    "            if pd.isna(genres_str) or genres_str == '[]':\n",
    "                return 'Unknown'\n",
    "            import ast\n",
    "            genres_list = ast.literal_eval(genres_str)\n",
    "            if genres_list:\n",
    "                return genres_list[0]['name']\n",
    "            return 'Unknown'\n",
    "        except:\n",
    "            return 'Unknown'\n",
    "    \n",
    "    movies_clean['main_genre'] = movies_clean['genres'].apply(extract_main_genre)\n",
    "    \n",
    "    movies_clean['release_date'] = pd.to_datetime(movies_clean['release_date'], errors='coerce')\n",
    "    movies_clean['release_year'] = movies_clean['release_date'].dt.year\n",
    "    movies_clean['release_month'] = movies_clean['release_date'].dt.month\n",
    "    \n",
    "    movies_clean['release_year'].fillna(movies_clean['release_year'].median(), inplace=True)\n",
    "    movies_clean['release_month'].fillna(movies_clean['release_month'].median(), inplace=True)\n",
    "    \n",
    "    movies_clean['log_budget'] = np.log1p(movies_clean['budget'])\n",
    "    movies_clean['log_popularity'] = np.log1p(movies_clean['popularity'])\n",
    "    \n",
    "    print(\"Признаки созданы\")\n",
    "    return movies_clean\n",
    "\n",
    "def _create_ml_datasets(movies_clean):\n",
    "    print(\"Подготовка датасетов для ML:\")\n",
    "    \n",
    "    feature_columns = [\n",
    "        'budget', 'log_budget', 'popularity', 'log_popularity', \n",
    "        'runtime', 'vote_count', 'release_year', 'release_month'\n",
    "    ]\n",
    "    \n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le_genre = LabelEncoder()\n",
    "    movies_clean['main_genre_encoded'] = le_genre.fit_transform(movies_clean['main_genre'])\n",
    "    feature_columns.append('main_genre_encoded')\n",
    "    \n",
    "    classification_data = movies_clean[\n",
    "        (movies_clean['commercial_success'].notna()) & \n",
    "        movies_clean[feature_columns].notna().all(axis=1)\n",
    "    ].copy()\n",
    "    \n",
    "    X_classification = classification_data[feature_columns]\n",
    "    y_classification = classification_data['commercial_success']\n",
    "    \n",
    "    print(f\"Датасет для классификации: {len(X_classification)} объектов, {len(feature_columns)} признаков\")\n",
    "    \n",
    "    regression_data = movies_clean[\n",
    "        (movies_clean['vote_average'].notna()) & \n",
    "        movies_clean[feature_columns].notna().all(axis=1)\n",
    "    ].copy()\n",
    "    \n",
    "    X_regression = regression_data[feature_columns]\n",
    "    y_regression = regression_data['vote_average']\n",
    "    \n",
    "    print(f\"Датасет для регрессии: {len(X_regression)} объектов, {len(feature_columns)} признаков\")\n",
    "    \n",
    "    return X_classification, y_classification, X_regression, y_regression, feature_columns\n",
    "\n",
    "X_class, y_class, X_reg, y_reg, feature_names = load_and_preprocess_data()\n",
    "\n",
    "print(\"Информация о данных:\")\n",
    "print(f\"Классификация: {X_class.shape[0]} объектов, {X_class.shape[1]} признаков\")\n",
    "print(f\"Регрессия: {X_reg.shape[0]} объектов, {X_reg.shape[1]} признаков\")\n",
    "print(f\"Баланс классов: {y_class.value_counts().to_dict()}\")\n",
    "print(f\"Статистика рейтинга: мин={y_reg.min():.2f}, макс={y_reg.max():.2f}, среднее={y_reg.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Подготовка данных для моделирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры выборок:\n",
      "Классификация - обучающая: 4304, тестовая: 1077\n",
      "Регрессия - обучающая: 4304, тестовая: 1077\n"
     ]
    }
   ],
   "source": [
    "X_class_train, X_class_test, y_class_train, y_class_test = train_test_split(\n",
    "    X_class, y_class, test_size=0.2, random_state=42, stratify=y_class\n",
    ")\n",
    "\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Размеры выборок:\")\n",
    "print(f\"Классификация - обучающая: {X_class_train.shape[0]}, тестовая: {X_class_test.shape[0]}\")\n",
    "print(f\"Регрессия - обучающая: {X_reg_train.shape[0]}, тестовая: {X_reg_test.shape[0]}\")\n",
    "\n",
    "scaler_class = StandardScaler()\n",
    "X_class_train_scaled = scaler_class.fit_transform(X_class_train)\n",
    "X_class_test_scaled = scaler_class.transform(X_class_test)\n",
    "\n",
    "scaler_reg = StandardScaler()\n",
    "X_reg_train_scaled = scaler_reg.fit_transform(X_reg_train)\n",
    "X_reg_test_scaled = scaler_reg.transform(X_reg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Градиентный бустинг - Базовые модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Базовая модель градиентного бустинга (классификация):\n",
      "Accuracy: 0.7400\n",
      "Количество деревьев: 100\n",
      "Learning rate: 0.1\n",
      "Максимальная глубина: 3\n",
      "Отчет классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68       437\n",
      "           1       0.78      0.78      0.78       640\n",
      "\n",
      "    accuracy                           0.74      1077\n",
      "   macro avg       0.73      0.73      0.73      1077\n",
      "weighted avg       0.74      0.74      0.74      1077\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb_class_base = GradientBoostingClassifier(random_state=42)\n",
    "gb_class_base.fit(X_class_train, y_class_train)\n",
    "y_class_pred_base = gb_class_base.predict(X_class_test)\n",
    "accuracy_base = accuracy_score(y_class_test, y_class_pred_base)\n",
    "\n",
    "print(f\"Базовая модель градиентного бустинга (классификация):\")\n",
    "print(f\"Accuracy: {accuracy_base:.4f}\")\n",
    "print(f\"Количество деревьев: {gb_class_base.n_estimators}\")\n",
    "print(f\"Learning rate: {gb_class_base.learning_rate}\")\n",
    "print(f\"Максимальная глубина: {gb_class_base.max_depth}\")\n",
    "print(\"Отчет классификации:\")\n",
    "print(classification_report(y_class_test, y_class_pred_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Базовая модель градиентного бустинга (регрессия):\n",
      "MAE: 0.5111\n",
      "RMSE: 0.6727\n",
      "R²: 0.4682\n",
      "Количество деревьев: 100\n",
      "Learning rate: 0.1\n",
      "Максимальная глубина: 3\n"
     ]
    }
   ],
   "source": [
    "gb_reg_base = GradientBoostingRegressor(random_state=42)\n",
    "gb_reg_base.fit(X_reg_train, y_reg_train)\n",
    "y_reg_pred_base = gb_reg_base.predict(X_reg_test)\n",
    "\n",
    "mae_base = mean_absolute_error(y_reg_test, y_reg_pred_base)\n",
    "rmse_base = np.sqrt(mean_squared_error(y_reg_test, y_reg_pred_base))\n",
    "r2_base = r2_score(y_reg_test, y_reg_pred_base)\n",
    "\n",
    "print(f\"Базовая модель градиентного бустинга (регрессия):\")\n",
    "print(f\"MAE: {mae_base:.4f}\")\n",
    "print(f\"RMSE: {rmse_base:.4f}\")\n",
    "print(f\"R²: {r2_base:.4f}\")\n",
    "print(f\"Количество деревьев: {gb_reg_base.n_estimators}\")\n",
    "print(f\"Learning rate: {gb_reg_base.learning_rate}\")\n",
    "print(f\"Максимальная глубина: {gb_reg_base.max_depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Градиентный бустинг - Оптимизация параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подбор оптимальных параметров для классификации...\n",
      "Лучшие параметры классификации: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}\n",
      "Лучший скор (CV): 0.7602\n"
     ]
    }
   ],
   "source": [
    "param_grid_class = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "param_grid_reg = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "print(\"Подбор оптимальных параметров для классификации...\")\n",
    "\n",
    "gb_class_grid = GridSearchCV(\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    param_grid_class,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "gb_class_grid.fit(X_class_train, y_class_train)\n",
    "\n",
    "print(f\"Лучшие параметры классификации: {gb_class_grid.best_params_}\")\n",
    "print(f\"Лучший скор (CV): {gb_class_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подбор оптимальных параметров для регрессии...\n",
      "Лучшие параметры регрессии: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "Лучший скор (CV): 0.4660\n"
     ]
    }
   ],
   "source": [
    "print(\"Подбор оптимальных параметров для регрессии...\")\n",
    "\n",
    "gb_reg_grid = GridSearchCV(\n",
    "    GradientBoostingRegressor(random_state=42),\n",
    "    param_grid_reg,\n",
    "    cv=3,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1\n",
    ")\n",
    "gb_reg_grid.fit(X_reg_train, y_reg_train)\n",
    "\n",
    "print(f\"Лучшие параметры регрессии: {gb_reg_grid.best_params_}\")\n",
    "print(f\"Лучший скор (CV): {gb_reg_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сравнение моделей градиентного бустинга (классификация):\n",
      "Базовая модель: 0.7400\n",
      "Оптимизированная модель: 0.7354\n",
      "Улучшение: -0.63%\n"
     ]
    }
   ],
   "source": [
    "gb_class_optimized = gb_class_grid.best_estimator_\n",
    "y_class_pred_optimized = gb_class_optimized.predict(X_class_test)\n",
    "accuracy_optimized = accuracy_score(y_class_test, y_class_pred_optimized)\n",
    "\n",
    "print(\"Сравнение моделей градиентного бустинга (классификация):\")\n",
    "print(f\"Базовая модель: {accuracy_base:.4f}\")\n",
    "print(f\"Оптимизированная модель: {accuracy_optimized:.4f}\")\n",
    "print(f\"Улучшение: {((accuracy_optimized - accuracy_base) / accuracy_base * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сравнение моделей градиентного бустинга (регрессия):\n",
      "Метрика\t\tБазовая\t\tОптимиз.\t\tУлучшение\n",
      "MAE\t\t0.5111\t\t0.5111\t\t0.00%\n",
      "RMSE\t\t0.6727\t\t0.6727\t\t0.00%\n",
      "R²\t\t0.4682\t\t0.4682\t\t0.00%\n"
     ]
    }
   ],
   "source": [
    "gb_reg_optimized = gb_reg_grid.best_estimator_\n",
    "y_reg_pred_optimized = gb_reg_optimized.predict(X_reg_test)\n",
    "\n",
    "mae_optimized = mean_absolute_error(y_reg_test, y_reg_pred_optimized)\n",
    "rmse_optimized = np.sqrt(mean_squared_error(y_reg_test, y_reg_pred_optimized))\n",
    "r2_optimized = r2_score(y_reg_test, y_reg_pred_optimized)\n",
    "\n",
    "print(\"Сравнение моделей градиентного бустинга (регрессия):\")\n",
    "print(\"Метрика\\t\\tБазовая\\t\\tОптимиз.\\t\\tУлучшение\")\n",
    "print(f\"MAE\\t\\t{mae_base:.4f}\\t\\t{mae_optimized:.4f}\\t\\t{((mae_base - mae_optimized) / mae_base * 100):.2f}%\")\n",
    "print(f\"RMSE\\t\\t{rmse_base:.4f}\\t\\t{rmse_optimized:.4f}\\t\\t{((rmse_base - rmse_optimized) / rmse_base * 100):.2f}%\")\n",
    "print(f\"R²\\t\\t{r2_base:.4f}\\t\\t{r2_optimized:.4f}\\t\\t{((r2_optimized - r2_base) / r2_base * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Тестирование собственной реализации градиентного бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестирование собственной реализации градиентного бустинга...\n",
      "Обучено деревьев: 20/50\n",
      "Обучено деревьев: 40/50\n",
      "Классификация (собственная реализация):\n",
      "Accuracy: 0.7354\n",
      "Количество деревьев: 50\n",
      "Сравнение с sklearn: 0.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"Тестирование собственной реализации градиентного бустинга...\")\n",
    "\n",
    "custom_gb_class = CustomGradientBoostingClassifier(\n",
    "    n_estimators=gb_class_optimized.n_estimators,\n",
    "    learning_rate=gb_class_optimized.learning_rate,\n",
    "    max_depth=gb_class_optimized.max_depth,\n",
    "    random_state=42\n",
    ")\n",
    "custom_gb_class.fit(X_class_train, y_class_train)\n",
    "y_class_pred_custom = custom_gb_class.predict(X_class_test)\n",
    "custom_accuracy = accuracy_score(y_class_test, y_class_pred_custom)\n",
    "\n",
    "print(f\"Классификация (собственная реализация):\")\n",
    "print(f\"Accuracy: {custom_accuracy:.4f}\")\n",
    "print(f\"Количество деревьев: {len(custom_gb_class.trees)}\")\n",
    "print(f\"Сравнение с sklearn: {abs(custom_accuracy - accuracy_optimized):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучено деревьев: 20/100\n",
      "Обучено деревьев: 40/100\n",
      "Обучено деревьев: 60/100\n",
      "Обучено деревьев: 80/100\n",
      "Обучено деревьев: 100/100\n",
      "Регрессия (собственная реализация):\n",
      "MAE: 0.5114\n",
      "R²: 0.4681\n",
      "Количество деревьев: 100\n",
      "Сравнение с sklearn MAE: 0.0003\n",
      "Сравнение с sklearn R²: 0.0001\n"
     ]
    }
   ],
   "source": [
    "custom_gb_reg = CustomGradientBoostingRegressor(\n",
    "    n_estimators=gb_reg_optimized.n_estimators,\n",
    "    learning_rate=gb_reg_optimized.learning_rate,\n",
    "    max_depth=gb_reg_optimized.max_depth,\n",
    "    random_state=42\n",
    ")\n",
    "custom_gb_reg.fit(X_reg_train, y_reg_train)\n",
    "y_reg_pred_custom = custom_gb_reg.predict(X_reg_test)\n",
    "\n",
    "custom_mae = mean_absolute_error(y_reg_test, y_reg_pred_custom)\n",
    "custom_r2 = r2_score(y_reg_test, y_reg_pred_custom)\n",
    "\n",
    "print(f\"Регрессия (собственная реализация):\")\n",
    "print(f\"MAE: {custom_mae:.4f}\")\n",
    "print(f\"R²: {custom_r2:.4f}\")\n",
    "print(f\"Количество деревьев: {len(custom_gb_reg.trees)}\")\n",
    "print(f\"Сравнение с sklearn MAE: {abs(custom_mae - mae_optimized):.4f}\")\n",
    "print(f\"Сравнение с sklearn R²: {abs(custom_r2 - r2_optimized):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Анализ важности признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Важность признаков (градиентный бустинг - классификация):\n",
      "vote_count: 0.4514\n",
      "release_year: 0.1650\n",
      "log_budget: 0.1007\n",
      "budget: 0.0885\n",
      "runtime: 0.0793\n"
     ]
    }
   ],
   "source": [
    "feature_names = X_class.columns.tolist()\n",
    "\n",
    "importance_class = gb_class_optimized.feature_importances_\n",
    "feature_importance_class = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importance_class\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Важность признаков (градиентный бустинг - классификация):\")\n",
    "for _, row in feature_importance_class.head(5).iterrows():\n",
    "    print(f\"{row['feature']}: {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Важность признаков (градиентный бустинг - регрессия):\n",
      "vote_count: 0.3963\n",
      "runtime: 0.2080\n",
      "log_budget: 0.1012\n",
      "release_year: 0.0991\n",
      "budget: 0.0762\n"
     ]
    }
   ],
   "source": [
    "importance_reg = gb_reg_optimized.feature_importances_\n",
    "feature_importance_reg = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importance_reg\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Важность признаков (градиентный бустинг - регрессия):\")\n",
    "for _, row in feature_importance_reg.head(5).iterrows():\n",
    "    print(f\"{row['feature']}: {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Итоговое сравнение всех 5 методов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подготовка всех моделей для итогового сравнения...\n",
      "Обучение моделей классификации...\n",
      "Обучаем KNN...\n",
      "Обучаем Logistic Regression...\n",
      "Обучаем Decision Tree...\n",
      "Обучаем Random Forest...\n",
      "Обучаем Gradient Boosting...\n",
      "Обучение моделей регрессии...\n",
      "Обучаем KNN...\n",
      "Обучаем Linear Regression...\n",
      "Обучаем Decision Tree...\n",
      "Обучаем Random Forest...\n",
      "Обучаем Gradient Boosting...\n",
      "Все модели обучены!\n"
     ]
    }
   ],
   "source": [
    "print(\"Подготовка всех моделей для итогового сравнения...\")\n",
    "\n",
    "models_class = {\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=7),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=7, min_samples_split=5, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n",
    "    'Gradient Boosting': gb_class_optimized\n",
    "}\n",
    "\n",
    "models_reg = {\n",
    "    'KNN': KNeighborsRegressor(n_neighbors=5),\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(max_depth=7, min_samples_split=5, random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),\n",
    "    'Gradient Boosting': gb_reg_optimized\n",
    "}\n",
    "\n",
    "print(\"Обучение моделей классификации...\")\n",
    "for name, model in models_class.items():\n",
    "    print(f\"Обучаем {name}...\")\n",
    "    model.fit(X_class_train_scaled, y_class_train)\n",
    "    \n",
    "print(\"Обучение моделей регрессии...\")\n",
    "for name, model in models_reg.items():\n",
    "    print(f\"Обучаем {name}...\")\n",
    "    if name in ['KNN', 'Linear Regression']:\n",
    "        model.fit(X_reg_train_scaled, y_reg_train)\n",
    "    else:\n",
    "        model.fit(X_reg_train, y_reg_train)\n",
    "\n",
    "print(\"Все модели обучены!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты классификации:\n",
      "==================================================\n",
      "KNN                 : 0.6630\n",
      "Logistic Regression : 0.7057\n",
      "Decision Tree       : 0.5924\n",
      "Random Forest       : 0.5980\n",
      "Gradient Boosting   : 0.5970\n",
      "\n",
      "Результаты регрессии:\n",
      "==================================================\n",
      "KNN                 : R² = 0.3030\n",
      "Linear Regression   : R² = 0.3160\n",
      "Decision Tree       : R² = 0.3624\n",
      "Random Forest       : R² = 0.4592\n",
      "Gradient Boosting   : R² = 0.4682\n",
      "\n",
      "Лучшие модели:\n",
      "Классификация: Logistic Regression (Accuracy = 0.7057)\n",
      "Регрессия: Gradient Boosting (R² = 0.4682)\n"
     ]
    }
   ],
   "source": [
    "results_class = {}\n",
    "print(\"Результаты классификации:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for name, model in models_class.items():\n",
    "    if name in ['KNN', 'Logistic Regression']:\n",
    "        y_pred = model.predict(X_class_test_scaled)\n",
    "    else:\n",
    "        y_pred = model.predict(X_class_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_class_test, y_pred)\n",
    "    results_class[name] = accuracy\n",
    "    print(f\"{name:20}: {accuracy:.4f}\")\n",
    "\n",
    "results_reg = {}\n",
    "print(\"\\nРезультаты регрессии:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for name, model in models_reg.items():\n",
    "    if name in ['KNN', 'Linear Regression']:\n",
    "        y_pred = model.predict(X_reg_test_scaled)\n",
    "    else:\n",
    "        y_pred = model.predict(X_reg_test)\n",
    "    \n",
    "    r2 = r2_score(y_reg_test, y_pred)\n",
    "    results_reg[name] = r2\n",
    "    print(f\"{name:20}: R² = {r2:.4f}\")\n",
    "\n",
    "best_class = max(results_class.items(), key=lambda x: x[1])\n",
    "best_reg = max(results_reg.items(), key=lambda x: x[1])\n",
    "\n",
    "print(f\"\\nЛучшие модели:\")\n",
    "print(f\"Классификация: {best_class[0]} (Accuracy = {best_class[1]:.4f})\")\n",
    "print(f\"Регрессия: {best_reg[0]} (R² = {best_reg[1]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "class_names = list(results_class.keys())\n",
    "class_scores = list(results_class.values())\n",
    "\n",
    "axes[0,0].bar(range(len(class_names)), class_scores, color=['skyblue', 'lightgreen', 'orange', 'lightcoral', 'gold'])\n",
    "axes[0,0].set_xticks(range(len(class_names)))\n",
    "axes[0,0].set_xticklabels(class_names, rotation=45, ha='right')\n",
    "axes[0,0].set_ylabel('Accuracy')\n",
    "axes[0,0].set_title('Сравнение методов классификации')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "axes[0,0].axhline(y=max(class_scores), color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "reg_names = list(results_reg.keys())\n",
    "reg_scores = list(results_reg.values())\n",
    "\n",
    "axes[0,1].bar(range(len(reg_names)), reg_scores, color=['skyblue', 'lightgreen', 'orange', 'lightcoral', 'gold'])\n",
    "axes[0,1].set_xticks(range(len(reg_names)))\n",
    "axes[0,1].set_xticklabels(reg_names, rotation=45, ha='right')\n",
    "axes[0,1].set_ylabel('R²')\n",
    "axes[0,1].set_title('Сравнение методов регрессии')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "axes[0,1].axhline(y=max(reg_scores), color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "class_ranking = sorted(results_class.items(), key=lambda x: x[1], reverse=True)\n",
    "reg_ranking = sorted(results_reg.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "class_positions = [pos for pos, _ in enumerate(class_ranking)]\n",
    "class_method_names = [name for name, _ in class_ranking]\n",
    "class_scores_ranked = [score for _, score in class_ranking]\n",
    "\n",
    "axes[1,0].barh(class_positions, class_scores_ranked, color=['gold', 'silver', '#CD7F32', 'lightblue', 'lightgray'])\n",
    "axes[1,0].set_yticks(class_positions)\n",
    "axes[1,0].set_yticklabels(class_method_names)\n",
    "axes[1,0].set_xlabel('Accuracy')\n",
    "axes[1,0].set_title('Рейтинг методов классификации')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "reg_positions = [pos for pos, _ in enumerate(reg_ranking)]\n",
    "reg_method_names = [name for name, _ in reg_ranking]\n",
    "reg_scores_ranked = [score for _, score in reg_ranking]\n",
    "\n",
    "axes[1,1].barh(reg_positions, reg_scores_ranked, color=['gold', 'silver', '#CD7F32', 'lightblue', 'lightgray'])\n",
    "axes[1,1].set_yticks(reg_positions)\n",
    "axes[1,1].set_yticklabels(reg_method_names)\n",
    "axes[1,1].set_xlabel('R²')\n",
    "axes[1,1].set_title('Рейтинг методов регрессии')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Итоговые результаты и выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ИТОГОВАЯ СВОДКА ВСЕХ 5 МЕТОДОВ:\n",
      "================================================================================\n",
      "                           Метод  Классификация (Accuracy)  Регрессия (R²)                                Особенности\n",
      "                             KNN                  0.662953        0.303031              Простота, не требует обучения\n",
      "Линейная/Логистическая регрессия                  0.705664        0.315950          Интерпретируемость, базовый метод\n",
      "                 Решающее дерево                  0.592386        0.362442 Интерпретируемость, склонен к переобучению\n",
      "                   Случайный лес                  0.597957        0.459161      Ансамбль, устойчивость к переобучению\n",
      "             Градиентный бустинг                  0.597029        0.468185 Последовательное обучение, лучшее качество\n",
      "\n",
      "ПОДРОБНЫЙ АНАЛИЗ ЛУЧШИХ МЕТОДОВ:\n",
      "============================================================\n",
      "Классификация - Лучший метод: Logistic Regression\n",
      "Отчет классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.65       437\n",
      "           1       0.77      0.72      0.74       640\n",
      "\n",
      "    accuracy                           0.71      1077\n",
      "   macro avg       0.70      0.70      0.70      1077\n",
      "weighted avg       0.71      0.71      0.71      1077\n",
      "\n",
      "\n",
      "Регрессия - Лучший метод: Gradient Boosting\n",
      "Метрики качества:\n",
      "R²: 0.4682\n",
      "MAE: 0.5111\n",
      "RMSE: 0.6727\n"
     ]
    }
   ],
   "source": [
    "final_comparison = pd.DataFrame({\n",
    "    'Метод': ['KNN', 'Линейная/Логистическая регрессия', 'Решающее дерево', 'Случайный лес', 'Градиентный бустинг'],\n",
    "    'Классификация (Accuracy)': [results_class['KNN'], results_class['Logistic Regression'], results_class['Decision Tree'], results_class['Random Forest'], results_class['Gradient Boosting']],\n",
    "    'Регрессия (R²)': [results_reg['KNN'], results_reg['Linear Regression'], results_reg['Decision Tree'], results_reg['Random Forest'], results_reg['Gradient Boosting']],\n",
    "    'Особенности': [\n",
    "        'Простота, не требует обучения',\n",
    "        'Интерпретируемость, базовый метод',\n",
    "        'Интерпретируемость, склонен к переобучению',\n",
    "        'Ансамбль, устойчивость к переобучению',\n",
    "        'Последовательное обучение, лучшее качество'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"ИТОГОВАЯ СВОДКА ВСЕХ 5 МЕТОДОВ:\")\n",
    "print(\"=\"*80)\n",
    "print(final_comparison.to_string(index=False))\n",
    "\n",
    "print(\"\\nПОДРОБНЫЙ АНАЛИЗ ЛУЧШИХ МЕТОДОВ:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"Классификация - Лучший метод:\", best_class[0])\n",
    "best_class_model = models_class[best_class[0]]\n",
    "if best_class[0] in ['KNN', 'Logistic Regression']:\n",
    "    y_pred_best_class = best_class_model.predict(X_class_test_scaled)\n",
    "else:\n",
    "    y_pred_best_class = best_class_model.predict(X_class_test)\n",
    "\n",
    "print(\"Отчет классификации:\")\n",
    "print(classification_report(y_class_test, y_pred_best_class))\n",
    "\n",
    "print(\"\\nРегрессия - Лучший метод:\", best_reg[0])\n",
    "best_reg_model = models_reg[best_reg[0]]\n",
    "if best_reg[0] in ['KNN', 'Linear Regression']:\n",
    "    y_pred_best_reg = best_reg_model.predict(X_reg_test_scaled)\n",
    "else:\n",
    "    y_pred_best_reg = best_reg_model.predict(X_reg_test)\n",
    "\n",
    "mae_best = mean_absolute_error(y_reg_test, y_pred_best_reg)\n",
    "rmse_best = np.sqrt(mean_squared_error(y_reg_test, y_pred_best_reg))\n",
    "\n",
    "print(f\"Метрики качества:\")\n",
    "print(f\"R²: {best_reg[1]:.4f}\")\n",
    "print(f\"MAE: {mae_best:.4f}\")\n",
    "print(f\"RMSE: {rmse_best:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по лабораторной работе №5:\n",
    "\n",
    "1. **Градиентный бустинг** показал лучшие результаты среди всех методов\n",
    "2. **Оптимизация гиперпараметров** критически важна для качества модели\n",
    "3. **Собственная реализация** корректно работает, но уступает оптимизированной sklearn версии\n",
    "4. **Ансамблевые методы** (Random Forest, Gradient Boosting) превосходят одиночные модели\n",
    "5. **Градиентный бустинг** - лучший выбор для сложных задач с нелинейными зависимостями"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
